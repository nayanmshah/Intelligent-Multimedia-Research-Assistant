"""
# ðŸ§  Intelligent Multimedia Research Assistant (IMRA)

A smart assistant that ingests documents and returns contextual, AI-generated answers using LangChain + HuggingFace + FAISS + RAG architecture.

## Features
- PDF ingestion
- LLM-based QA (Retrieval Augmented Generation)
- HuggingFace LLM backend
- Optional image generation using diffusion models

## Setup
1. Install dependencies
```bash
pip install -r requirements.txt
```
2. Add Hugging Face token to `.env`
```
HUGGINGFACEHUB_API_TOKEN=your_token_here
```
3. Run the app
```bash
streamlit run ui/app.py
```
"""

## Application URL
- The application is deployed at https://multimediaresearchassistant.streamlit.app/ and is available for all.

## Output before tuning the model for resume

![Screenshot 2025-04-23 at 9 09 23â€¯AM](https://github.com/user-attachments/assets/e2cb4204-398a-4fc7-9410-eeeb5188dd14)

![Screenshot 2025-04-22 at 10 17 48â€¯PM](https://github.com/user-attachments/assets/3fad8b8d-f1ab-4908-a37d-b9c4de0bf55e)

![Screenshot 2025-04-23 at 12 54 16â€¯PM](https://github.com/user-attachments/assets/6dde3301-c206-42aa-aaf5-dec55b5a038f)

![Screenshot 2025-04-23 at 12 55 54â€¯PM](https://github.com/user-attachments/assets/3d701650-8155-4aba-a13e-bacf88deecd6)


## Output after tuning the model for resume

![Screenshot 2025-04-24 at 1 57 56â€¯PM](https://github.com/user-attachments/assets/268cbd14-3ac5-4fe3-a05a-75237b9c175b)

![Screenshot 2025-04-24 at 1 59 00â€¯PM](https://github.com/user-attachments/assets/396935a9-ee53-4bf6-b4a6-00422b5b2ca9)




